# -*- coding: utf-8 -*-
"""Task 2__ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bbB95WBNNaxFxr92qEQJzkGAlP5Lllp8
"""

# Importing necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_curve, auc

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout

# Loading the datasets
traindata = pd.read_csv('KDDTrain+.csv', header=None)
testdata = pd.read_csv('KDDTest+.csv', header=None)

# Separate features and labels properly
X = traindata.iloc[:, :41].copy()
Y = traindata.iloc[:, 41].copy()

T = testdata.iloc[:, :41].copy()
C = testdata.iloc[:, 41].copy()

# Handle missing values
X = X.fillna(0)
T = T.fillna(0)

# Encode categorical columns
categorical_columns = [1, 2, 3]  # protocol_type, service, flag

for col in categorical_columns:
    le = LabelEncoder()
    X.iloc[:, col] = le.fit_transform(X.iloc[:, col])

    mapping = dict(zip(le.classes_, range(len(le.classes_))))
    T.iloc[:, col] = T.iloc[:, col].map(mapping).fillna(-1).astype(int)

# Encode target labels
le_y = LabelEncoder()
Y = le_y.fit_transform(Y)

le_c = LabelEncoder()
C = le_c.fit_transform(C)

# Standardize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
T_scaled = scaler.transform(T)

# Apply PCA (retain 95% variance)
pca = PCA(n_components=0.95)
X_pca = pca.fit_transform(X_scaled)
T_pca = pca.transform(T_scaled)

# Split train set
X_train, X_val, y_train, y_val = train_test_split(X_pca, Y, test_size=0.2, random_state=42)

# ===== Random Forest =====
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_val)

# ===== CNN =====
# Prepare data for CNN (reshape)
X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_val_cnn = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)

cnn_model = Sequential([
    Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),
    MaxPooling1D(pool_size=2),
    Dropout(0.3),
    Conv1D(64, kernel_size=3, activation='relu'),
    MaxPooling1D(pool_size=2),
    Dropout(0.3),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(len(np.unique(y_train)), activation='softmax')
])

cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
cnn_model.fit(X_train_cnn, y_train, epochs=15, batch_size=64, validation_data=(X_val_cnn, y_val), verbose=1)

y_pred_cnn_proba = cnn_model.predict(X_val_cnn)
y_pred_cnn = np.argmax(y_pred_cnn_proba, axis=1)

# ===== EVALUATION SECTION =====
models = {
    'Random Forest': (y_val, y_pred_rf),
    'CNN': (y_val, y_pred_cnn)
}

# ---- Print Accuracy and Classification Report ----
for model_name, (true_labels, predictions) in models.items():
    acc = accuracy_score(true_labels, predictions)
    print(f"\n=== {model_name} ===")
    print(f"Accuracy: {acc:.4f}")
    print("Classification Report:")
    print(classification_report(true_labels, predictions))

# ---- Confusion Matrices ----
fig, axs = plt.subplots(1, 3, figsize=(24, 6))
for idx, (model_name, (true_labels, predictions)) in enumerate(models.items()):
    cm = confusion_matrix(true_labels, predictions)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axs[idx])
    axs[idx].set_title(f'{model_name} Confusion Matrix')
    axs[idx].set_xlabel('Predicted')
    axs[idx].set_ylabel('Actual')
plt.tight_layout()
plt.show()

# ---- Precision-Recall Curve ----
# Find the index of "normal" class (usually named 'normal')
normal_class = np.where(le_y.classes_ == 'normal')[0][0]

def binarize(y, normal_class_idx):
    return (y == normal_class_idx).astype(int)

y_val_bin = binarize(y_val, normal_class)

plt.figure(figsize=(10, 7))
for model_name, (true_labels, predictions) in models.items():
    preds_bin = binarize(predictions, normal_class)
    precision, recall, _ = precision_recall_curve(y_val_bin, preds_bin)
    pr_auc = auc(recall, precision)
    plt.plot(recall, precision, label=f'{model_name} (AUC={pr_auc:.2f})')

plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curves for "Normal" Class')
plt.legend()
plt.grid()
plt.show()